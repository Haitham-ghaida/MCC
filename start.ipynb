{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import premise as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2io as bi\n",
    "import bw2data as bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.projects.set_current('MCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biosphere database already present!!! No setup is needed\n"
     ]
    }
   ],
   "source": [
    "bi.bw2setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database has already been imported\n"
     ]
    }
   ],
   "source": [
    "ei391cdir = \"/home/haithamth/Documents/ecoinvent/ecoin_cuttoff_391/ecoinvent 3.9.1_cutoff_ecoSpold02/datasets\"\n",
    "data_base_name = \"ecoinvent-3.9.1-cuttoff\"\n",
    "if data_base_name in bd.databases:\n",
    "    print(\"Database has already been imported\")\n",
    "else:\n",
    "    ei391c = bi.SingleOutputEcospold2Importer(ei391cdir, data_base_name)\n",
    "    ei391c.apply_strategies()\n",
    "    ei391c.statistics()\n",
    "\n",
    "    #ei39.drop_unlinked(True)\n",
    "    ei391c.write_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from premise import NewDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndb = NewDatabase(\n",
    "#     scenarios=[\n",
    "#         {\"model\":\"image\", \"pathway\":\"SSP2-RCP19\", \"year\":2020},\n",
    "#         {\"model\":\"image\", \"pathway\":\"SSP2-RCP26\", \"year\":2020},\n",
    "#         {\"model\":\"image\", \"pathway\":\"SSP2-RCP19\", \"year\":2030},\n",
    "#         {\"model\":\"image\", \"pathway\":\"SSP2-RCP26\", \"year\":2030},\n",
    "#         {\"model\":\"image\", \"pathway\":\"SSP2-RCP19\", \"year\":2040},\n",
    "#         {\"model\":\"image\", \"pathway\":\"SSP2-RCP26\", \"year\":2040},\n",
    "#     ],\n",
    "#     source_db=\"ecoinvent-3.9.1-cuttoff\", # <-- name of the database in the BW2 project. Must be a string.\n",
    "#     source_version=\"3.9.1\", # <-- version of ecoinvent. Can be \"3.5\", \"3.6\", \"3.7\" or \"3.8\". Must be a string.\n",
    "#     key='tUePmX_S5B8ieZkkM7WUU2CnO8SmShwmAeWK9x2rTFo=', # <-- decryption key\n",
    "#     # to be requested from the library maintainers if you want ot use default scenarios included in `premise`\n",
    "#     use_multiprocessing=True # <-- set to True if you want to use multiprocessing\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndb.update_electricity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndb.write_db_to_brightway([\"SSP2-RCP19_2020\",\"SSP2-RCP26_2020\", \"SSP2-RCP19_2030\",\"SSP2-RCP26_2030\", \"SSP2-RCP19_2040\",\"SSP2-RCP26_2040\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecn = bd.Database(\"ecoinvent-3.9.1-cuttoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ecoinvent-3.9.1-cuttoff', '92d2cd69b744fb751c6e0751c3a2b5a6')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecn.search('recycling')[0].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "class Product:\n",
    "    '''This class represents a product in the system, it should take care of the following:\n",
    "    - Create a unique id for each product\n",
    "    - Create a unique serial number for each product\n",
    "    - Keep track of the product's service life\n",
    "    '''\n",
    "    # keep track of all instances of the class\n",
    "    instances = []\n",
    "    def __init__(self, name: str, amount: float | int, unit: str, service_life: int = None, production_lci: str = None, eol_lci: tuple[str,str] = None):\n",
    "        # randomly generated id\n",
    "        self.random_id = uuid.uuid4().hex\n",
    "        self.name = name\n",
    "        self.amount = amount\n",
    "        self.unit = unit\n",
    "        self.production_lci = production_lci\n",
    "        self.service_life = service_life\n",
    "        self.eol_lci = eol_lci\n",
    "        self.embodied_impacts = {}\n",
    "        self.instances.append(self) # keep track of all instances of the class\n",
    "\n",
    "    # better representation of the class for humans\n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}\"\n",
    "    \n",
    "    def replacement_sn(self):\n",
    "        ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Product(name='green', amount=1, unit='kg', service_life=20, production_lci= 'd872e0d78319cb13e12b96de83e19dd7',\n",
    "            eol_lci= 'a5f2280b72eab45fac5be638870c61ae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = Product(name='rabbit', amount=2, unit='kg', service_life=16, production_lci='d872e0d78319cb13e12b96de83e19dd7',\n",
    "             eol_lci= '92d2cd69b744fb751c6e0751c3a2b5a6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mfa:\n",
    "    '''\n",
    "    This class represents a material flow analysis, it should take care of the following:\n",
    "    - Create a time line for the analysis\n",
    "    - Create a list of points in time where replacements occur\n",
    "    '''\n",
    "    def __init__(self, start: int = 2020, end: int = 2080, time_step: int = 10):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.time_step = time_step\n",
    "        self.time_line = list(range(self.start, self.end+1, self.time_step)) # create a time line\n",
    "        self.points = []\n",
    "        self.embodied_impacts = {} # not currently used\n",
    "        self.max_year = self.get_max_db_year()\n",
    "        \n",
    "    \n",
    "    def add_points(self, product: Product):\n",
    "        '''\n",
    "        This function adds points to the time line where replacements occur'''\n",
    "        first_repl = product.service_life + self.start\n",
    "        \n",
    "        for i in range(first_repl, self.end-1, product.service_life):\n",
    "            self.points.append((i, product))\n",
    "        # clean duplicates\n",
    "        self.points = list(set(self.points))\n",
    "        # sort by year\n",
    "        self.points = sorted(self.points, key=lambda x: x[0])\n",
    "        return self.points\n",
    "    \n",
    "    \n",
    "    def create_time_line_dict(self):\n",
    "        '''\n",
    "        This function creates a dictionary of databases for each year in the time line'''\n",
    "        # initialize a dictionary to store yearly databases\n",
    "        yearly_databases = {}\n",
    "        # iterate through all years in the time line\n",
    "        for year in self.time_line:\n",
    "            # initialize an empty list for each year\n",
    "            yearly_databases[year] = []\n",
    "        # iterate through all databases in the project\n",
    "        for db in bd.databases:\n",
    "            # split the database name by underscore ***IMPORTANT*** pay attention the the naming convention of the databases it has to be SPPX-RPCxx_YYYY\n",
    "            db_processed = str(db).split(\"_\")\n",
    "            if db_processed[0] == 'ecoinvent-3.9.1-cuttoff':\n",
    "                ecoinvent = db\n",
    "            # if the database name has more than one element after splitting by underscore, then it is a scenario database\n",
    "            elif len(db_processed) > 1:\n",
    "                yearly_databases[int(db_processed[1])].append(db)\n",
    "        return yearly_databases\n",
    "    \n",
    "    \n",
    "    def get_max_db_year(self):\n",
    "        '''This gives you the last(max) year in the dictionary where databases exist'''\n",
    "        db_dict =  self.create_time_line_dict()\n",
    "        for year in reversed(sorted(db_dict.keys())):\n",
    "            if len(db_dict[year]) > 0:\n",
    "                return year\n",
    "            \n",
    "    def clean_list_for_lca(self):\n",
    "        '''this function provides the a list of tuples, the first value of the tuple is the year and the second value is the code of the activity'''\n",
    "        # initialize an empty list\n",
    "        clean_list = []\n",
    "        for point in self.points:\n",
    "            clean_list.append((point[0], point[1].production_lci))\n",
    "            clean_list.append((point[0], point[1].eol_lci))\n",
    "        return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = Mfa(start=2020, end=2050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2036, rabbit), (2040, green)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.add_points(p)\n",
    "tl.add_points(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2036, 'd872e0d78319cb13e12b96de83e19dd7'),\n",
       " (2036, '92d2cd69b744fb751c6e0751c3a2b5a6'),\n",
       " (2040, 'd872e0d78319cb13e12b96de83e19dd7'),\n",
       " (2040, 'a5f2280b72eab45fac5be638870c61ae')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.clean_list_for_lca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bw2calc as bc\n",
    "# class ProLCA:\n",
    "#     '''\n",
    "#     This class should take care of the following:\n",
    "#     - Create a production lca for each product\n",
    "#     - Create a time line based lca for each product\n",
    "#     - Create a future lca for each product\n",
    "#     - Create a future lca for the whole system\n",
    "#     '''\n",
    "#     def __init__(self, products: list[Product], mfa: Mfa, methods: list[tuple[str,str,str]] = [('EF v3.0 EN15804', 'climate change', 'global warming potential (GWP100)')]):\n",
    "#         self.products = products\n",
    "#         self.mfa = mfa\n",
    "#         self.methods = methods\n",
    "#         self.yearly_databases = mfa.create_time_line_dict()\n",
    "    \n",
    "    \n",
    "#     def database_chooser(self, year):\n",
    "#         '''\n",
    "#         This function chooses the appropriate database(s) based on the year'''\n",
    "#         available_years = self.yearly_databases.keys()\n",
    "#         # make sure that the function that create_time_line_dict is called before this function and a dictionary of yearly databases is created\n",
    "#         assert len(available_years) > 0, \"Please create a dictionary of yearly databases first\"\n",
    "#         # check if the year is in the available years\n",
    "#         if year in available_years:\n",
    "#             # just return the database for that year\n",
    "#             return self.yearly_databases[year]\n",
    "#         # if the year is not in the available years, then check if it is less than the minimum year\n",
    "#         elif year < min(available_years):\n",
    "#             return self.yearly_databases[min(available_years)]\n",
    "#         # if the year is not in the available years, then check if it is greater than the maximum year\n",
    "#         elif year > max(available_years):\n",
    "#             return self.yearly_databases[max(available_years)]\n",
    "#         else:\n",
    "#             # round down to the nearest year\n",
    "#             return self.yearly_databases[year - (year % 10)]\n",
    "        \n",
    "    \n",
    "#     def time_line_based_renovation_lca(self):\n",
    "#         '''\n",
    "#         This function calculates the production lca for each product in the time line\n",
    "#         it mainly takes care of the impacts of the products needed for renovation'''\n",
    "#         results_dict = {}\n",
    "#         for point in self.mfa.points:\n",
    "#             for product in self.products:\n",
    "#                 # Check if the second element in `point` equals `product`\n",
    "#                 if point[1] == product:\n",
    "#                     # Choose the appropriate database(s) based on the year\n",
    "#                     dbs = self.database_chooser(year=point[0])\n",
    "                    \n",
    "#                     # Iterate through all chosen databases\n",
    "#                     for db in dbs:\n",
    "#                         # Construct a unique key for storing results\n",
    "#                         result_key = f\"{point[0]}_{product}_{db}\"\n",
    "#                         # Ensure fetched_db returns the expected database\n",
    "#                         fetched_db = bd.Database(str(db))\n",
    "                        \n",
    "#                         # Ensure this returns the expected activity\n",
    "#                         activity = fetched_db.get(product.production_lci[1])\n",
    "                        \n",
    "#                         # Define the functional unit for the LCA\n",
    "#                         amount = product.amount\n",
    "#                         fu = {activity: amount}\n",
    "                        \n",
    "#                         # Initialize the LCA with the first method and calculate impacts\n",
    "#                         lca = bc.LCA(fu, self.methods[0])\n",
    "#                         lca.lci()\n",
    "#                         lca.lcia()\n",
    "                        \n",
    "#                         # Initialize a list to store impact scores for all methods\n",
    "#                         impacts = [lca.score]\n",
    "                        \n",
    "#                         # If there are additional methods, switch methods and calculate additional impacts\n",
    "#                         if len(self.methods) > 1:    \n",
    "#                             for method in self.methods[1:]:\n",
    "#                                 lca.switch_method(method)\n",
    "#                                 lca.lcia()\n",
    "#                                 impacts.append(lca.score)\n",
    "                        \n",
    "#                         # Store all calculated impacts in the results dictionary\n",
    "#                         results_dict[result_key] = impacts\n",
    "#         return results_dict\n",
    "    \n",
    "#     def time_line_based_eol_renovation_lca(self):\n",
    "#         '''\n",
    "#         This function calculates the eol lca for each product in the time line, basically the\n",
    "#         same as the time_line_based_renovation_lca function but with different lci activity\n",
    "#         it takes care of the eol of products that are replaced or renovated'''\n",
    "#         results_dict = {}\n",
    "#         for point in self.mfa.points:\n",
    "#             for product in self.products:\n",
    "#                 # Check if the second element in `point` equals `product`\n",
    "#                 if point[1] == product:\n",
    "#                     # Choose the appropriate database(s) based on the year\n",
    "#                     dbs = self.database_chooser(year=point[0])\n",
    "                    \n",
    "#                     # Iterate through all chosen databases\n",
    "#                     for db in dbs:\n",
    "#                         # Construct a unique key for storing results\n",
    "#                         result_key = f\"{point[0]}_{product}_{db}\"\n",
    "#                         # Ensure fetched_db returns the expected database\n",
    "#                         fetched_db = bd.Database(str(db))\n",
    "                        \n",
    "#                         # Ensure this returns the expected activity\n",
    "#                         activity = fetched_db.get(product.eol_lci[1])\n",
    "                        \n",
    "#                         # Define the functional unit for the LCA\n",
    "#                         amount = product.amount\n",
    "#                         fu = {activity: amount}\n",
    "                        \n",
    "#                         # Initialize the LCA with the first method and calculate impacts\n",
    "#                         lca = bc.LCA(fu, self.methods[0])\n",
    "#                         lca.lci()\n",
    "#                         lca.lcia()\n",
    "                        \n",
    "#                         # Initialize a list to store impact scores for all methods\n",
    "#                         impacts = [lca.score]\n",
    "                        \n",
    "#                         # If there are additional methods, switch methods and calculate additional impacts\n",
    "#                         if len(self.methods) > 1:    \n",
    "#                             for method in self.methods[1:]:\n",
    "#                                 lca.switch_method(method)\n",
    "#                                 lca.lcia()\n",
    "#                                 impacts.append(lca.score)\n",
    "                        \n",
    "#                         # Store all calculated impacts in the results dictionary\n",
    "#                         results_dict[result_key] = impacts\n",
    "#         return results_dict\n",
    "    \n",
    "#     def production_lca(self, db = 'ecoinvent-3.9.1-cuttoff'):\n",
    "#         results_dict = {}\n",
    "#         for product in self.products:            \n",
    "#             # Construct a unique key for storing results\n",
    "#             result_key = f\"{self.mfa.start}_{product}_{db}\"\n",
    "            \n",
    "#             fetched_db = bd.Database(str(db))\n",
    "#             # Ensure this returns the expected activity\n",
    "#             activity = fetched_db.get(product.production_lci[1])\n",
    "            \n",
    "#             # Define the functional unit for the LCA\n",
    "#             amount = product.amount\n",
    "#             fu = {activity: amount}\n",
    "            \n",
    "#             # Initialize the LCA with the first method and calculate impacts\n",
    "#             lca = bc.LCA(fu, self.methods[0])\n",
    "#             lca.lci()\n",
    "#             lca.lcia()\n",
    "            \n",
    "#             # Initialize a list to store impact scores for all methods\n",
    "#             impacts = [lca.score]\n",
    "            \n",
    "#             # If there are additional methods, switch methods and calculate additional impacts\n",
    "#             if len(self.methods) > 1:    \n",
    "#                 for method in self.methods[1:]:\n",
    "#                     lca.switch_method(method)\n",
    "#                     lca.lcia()\n",
    "#                     impacts.append(lca.score)\n",
    "            \n",
    "#             # Store all calculated impacts in the results dictionary\n",
    "#             results_dict[result_key] = impacts\n",
    "#         return results_dict\n",
    "    \n",
    "#     def eol_lca(self):\n",
    "#         results_dict = {}\n",
    "#         max_db_year = self.mfa.get_max_db_year()\n",
    "#         dbs = self.database_chooser(max_db_year)\n",
    "#         for product in self.products:\n",
    "#             for db in dbs:\n",
    "#                 # Construct a unique key for storing results\n",
    "#                 result_key = f\"{self.mfa.end}_{product}_{db}\"\n",
    "                \n",
    "#                 fetched_db = bd.Database(str(db))\n",
    "#                 # Ensure this returns the expected activity\n",
    "#                 activity = fetched_db.get(product.production_lci[1])\n",
    "                \n",
    "#                 # Define the functional unit for the LCA\n",
    "#                 amount = product.amount\n",
    "#                 fu = {activity: amount}\n",
    "                \n",
    "#                 # Initialize the LCA with the first method and calculate impacts\n",
    "#                 lca = bc.LCA(fu, self.methods[0])\n",
    "#                 lca.lci()\n",
    "#                 lca.lcia()\n",
    "                \n",
    "#                 # Initialize a list to store impact scores for all methods\n",
    "#                 impacts = [lca.score]\n",
    "                \n",
    "#                 # If there are additional methods, switch methods and calculate additional impacts\n",
    "#                 if len(self.methods) > 1:    \n",
    "#                     for method in self.methods[1:]:\n",
    "#                         lca.switch_method(method)\n",
    "#                         lca.lcia()\n",
    "#                         impacts.append(lca.score)\n",
    "                \n",
    "#                 # Store all calculated impacts in the results dictionary\n",
    "#                 results_dict[result_key] = impacts\n",
    "#         return results_dict\n",
    "    \n",
    "#     def heating_electricity_lca(self):\n",
    "#         pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2calc as bc\n",
    "class ProLCA:\n",
    "    '''\n",
    "    This class should take care of the following:\n",
    "    - Create a production lca for each product\n",
    "    - Create a time line based lca for each product\n",
    "    - Create a future lca for each product\n",
    "    - Create a future lca for the whole system\n",
    "    '''\n",
    "    def __init__(self, activities_and_years: list[tuple[str, int]],\n",
    "                 methods: list[tuple[str,str,str]] = [('EF v3.0 EN15804', 'climate change', 'global warming potential (GWP100)'),], yearly_databases: dict = None):\n",
    "        self.activities_and_years = activities_and_years\n",
    "        self.methods = methods\n",
    "        self.yearly_databases = yearly_databases\n",
    "        self.results = {}\n",
    "        self.results_aggregated = {}\n",
    "        \n",
    "    def database_chooser(self, year):\n",
    "        '''\n",
    "        This function chooses the appropriate database(s) based on the year'''\n",
    "        available_years = self.yearly_databases.keys()\n",
    "        # make sure that the function that create_time_line_dict is called before this function and a dictionary of yearly databases is created\n",
    "        assert len(available_years) > 0, \"Please create a dictionary of yearly databases first\"\n",
    "        # check if the year is in the available years\n",
    "        if year in available_years:\n",
    "            # just return the database for that year\n",
    "            return self.yearly_databases[year]\n",
    "        # if the year is not in the available years, then check if it is less than the minimum year\n",
    "        elif year < min(available_years):\n",
    "            return self.yearly_databases[min(available_years)]\n",
    "        # if the year is not in the available years, then check if it is greater than the maximum year\n",
    "        elif year > max(available_years):\n",
    "            return self.yearly_databases[max(available_years)]\n",
    "        else:\n",
    "            # round down to the nearest year\n",
    "            return self.yearly_databases[year - (year % 10)]\n",
    "\n",
    "    def give_me_embodied(self):\n",
    "        '''give me the lca please'''\n",
    "        # initialize an empty dictionary to store results\n",
    "        results_dict = {}\n",
    "        # iterate through all years in the time line\n",
    "        for year, activity in self.activities_and_years:            \n",
    "            # Choose the appropriate database(s) based on the year\n",
    "            dbs = self.database_chooser(year)\n",
    "            # Iterate through all chosen databases\n",
    "            for db in dbs:\n",
    "                # check if year and activity are already in the results dictionary if so, skip\n",
    "                if (year, activity, db) in results_dict.keys():\n",
    "                    continue\n",
    "                # Construct a unique key for storing results\n",
    "                result_key = (year, activity, db)\n",
    "                # get the activity from the database\n",
    "                demand = bd.get_activity((str(db), activity))\n",
    "                # Define the functional unit for the LCA\n",
    "                amount = 1\n",
    "                fu = {demand: amount}\n",
    "                # Initialize the LCA with the first method and calculate impacts\n",
    "                lca = bc.LCA(fu, self.methods[0])\n",
    "                lca.lci()\n",
    "                lca.lcia()\n",
    "                impacts = [lca.score]\n",
    "                # If there are additional methods, switch methods and calculate additional impacts\n",
    "                if len(self.methods) > 1:    \n",
    "                    for method in self.methods[1:]:\n",
    "                        lca.switch_method(method)\n",
    "                        lca.lcia()\n",
    "                        impacts.append(lca.score)\n",
    "\n",
    "                # Store all calculated impacts in the results dictionary\n",
    "                results_dict[result_key] = impacts\n",
    "        return results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca2 = ProLCA(activities_and_years=tl.clean_list_for_lca(), yearly_databases=tl.create_time_line_dict(), methods=[('EF v3.0 EN15804', 'climate change', 'global warming potential (GWP100)'), ('EF v3.0 EN15804', 'acidification', 'accumulated exceedance (AE)')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = lca2.give_me_embodied()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2036,\n",
       "  'd872e0d78319cb13e12b96de83e19dd7',\n",
       "  'SSP2-RCP19_2030'): [1.704690182464366, 0.0061609604473516445],\n",
       " (2036,\n",
       "  'd872e0d78319cb13e12b96de83e19dd7',\n",
       "  'SSP2-RCP26_2030'): [1.8391922681749882, 0.006631959383662307],\n",
       " (2036,\n",
       "  '92d2cd69b744fb751c6e0751c3a2b5a6',\n",
       "  'SSP2-RCP19_2030'): [0.15624137970034158, 0.0005927216833403848],\n",
       " (2036,\n",
       "  '92d2cd69b744fb751c6e0751c3a2b5a6',\n",
       "  'SSP2-RCP26_2030'): [0.17491520470736674, 0.0006474137351223672],\n",
       " (2040,\n",
       "  'd872e0d78319cb13e12b96de83e19dd7',\n",
       "  'SSP2-RCP19_2040'): [1.664174817198441, 0.005990449802518106],\n",
       " (2040,\n",
       "  'd872e0d78319cb13e12b96de83e19dd7',\n",
       "  'SSP2-RCP26_2040'): [1.7739710922834737, 0.006256772480144479],\n",
       " (2040,\n",
       "  'a5f2280b72eab45fac5be638870c61ae',\n",
       "  'SSP2-RCP19_2040'): [-0.061773535038168695, -0.000566683393259233],\n",
       " (2040,\n",
       "  'a5f2280b72eab45fac5be638870c61ae',\n",
       "  'SSP2-RCP26_2040'): [-0.0625605206879309, -0.0005684990797994778]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class GiveMeName:\n",
    "    \n",
    "    '''\n",
    "    an abstract class that takes care of the following:\n",
    "    - writing the results to excel\n",
    "    -aggregating the results\n",
    "    - TO BE DONE: aggregating the results based on the time line'''\n",
    "    \n",
    "    def aggregator(lcia_dict, product) -> dict:\n",
    "        # find all the keys in the lcia dictionary that contain the product code\n",
    "        keys = [key for key in lcia_dict.keys() if product.production_lci in key or product.eol_lci in key]\n",
    "        print(keys)\n",
    "\n",
    "        # Create a new dictionary that contains only the relevant keys\n",
    "        aggregated_lcia = {key: [x * product.amount for x in lcia_dict[key]] for key in keys}\n",
    "        \n",
    "        return aggregated_lcia\n",
    "    \n",
    "    def bd_get_activity(db_code) -> str:\n",
    "        # Your existing bd.get_activity logic\n",
    "        return bd.get_activity(db_code)['name']\n",
    "    \n",
    "    import pandas as pd\n",
    "\n",
    "    def poop_to_excel(data, bd_get_activity, output_file='output.xlsx') -> None:\n",
    "        \"\"\"\n",
    "        Generate an Excel file containing impacts data for each product.\n",
    "        \n",
    "        Parameters:\n",
    "            data (dict): Dictionary containing products and their respective embodied impacts data.\n",
    "            bd_get_activity (function): Function to retrieve activity name based on its code.\n",
    "            output_file (str): Name of the output Excel file.\n",
    "            \n",
    "        Returns:\n",
    "            None. Writes an Excel file to the specified output path.\n",
    "        \"\"\"\n",
    "        # Accumulating unique activity codes to reduce API/database calls\n",
    "        activity_codes = set([key[1] for product_data in resultv.values() for impacts_data in product_data.values() for key in impacts_data.keys()])\n",
    "                \n",
    "        activity_names = {code: bd_get_activity(('SSP2-RCP19_2030', code)) for code in activity_codes}\n",
    "        dfs = {}\n",
    "\n",
    "        # Looping through each product and its associated embodied impacts\n",
    "        for year, products_data in data.items():\n",
    "            for product_name, impacts_data in products_data.items():\n",
    "                for (year, activity_code, database), impacts in impacts_data.items():\n",
    "                    for impact_idx, impact in enumerate(impacts):\n",
    "                        if impact_idx not in dfs:\n",
    "                            dfs[impact_idx] = []\n",
    "\n",
    "                        dfs[impact_idx].append({\n",
    "                            'Year': year,\n",
    "                            'Database': database,\n",
    "                            'Activity': activity_names[activity_code],\n",
    "                            'Product': product_name,  # This will now correctly use the product name\n",
    "                            'Impact': impact\n",
    "                        })\n",
    "        # Convert data to multi-indexed DataFrames\n",
    "        dfs = {key: pd.DataFrame(value).set_index(['Year', 'Database', 'Activity', 'Product']) for key, value in dfs.items()}\n",
    "\n",
    "        for key, df in dfs.items():\n",
    "            # Sort by Year in other words combine all databases for each year\n",
    "            dfs[key] = df.sort_index(level='Year')\n",
    "\n",
    "        # Exporting the data to Excel\n",
    "        with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "            for sheet, df in dfs.items():\n",
    "                df.to_excel(writer, sheet_name=f'Impact_{sheet}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2036, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP19_2030'), (2036, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP26_2030'), (2040, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP19_2040'), (2040, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP26_2040'), (2040, 'a5f2280b72eab45fac5be638870c61ae', 'SSP2-RCP19_2040'), (2040, 'a5f2280b72eab45fac5be638870c61ae', 'SSP2-RCP26_2040')]\n",
      "[(2036, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP19_2030'), (2036, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP26_2030'), (2036, '92d2cd69b744fb751c6e0751c3a2b5a6', 'SSP2-RCP19_2030'), (2036, '92d2cd69b744fb751c6e0751c3a2b5a6', 'SSP2-RCP26_2030'), (2040, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP19_2040'), (2040, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP26_2040')]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for product in Product.instances:\n",
    "    product.embodied_impacts = GiveMeName.aggregator(results, product)\n",
    "    data[product.name] = product.embodied_impacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2036, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP19_2030'), (2036, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP26_2030'), (2040, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP19_2040'), (2040, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP26_2040'), (2040, 'a5f2280b72eab45fac5be638870c61ae', 'SSP2-RCP19_2040'), (2040, 'a5f2280b72eab45fac5be638870c61ae', 'SSP2-RCP26_2040')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(2036,\n",
       "  'd872e0d78319cb13e12b96de83e19dd7',\n",
       "  'SSP2-RCP19_2030'): [1.704690182464366, 0.0061609604473516445],\n",
       " (2036,\n",
       "  'd872e0d78319cb13e12b96de83e19dd7',\n",
       "  'SSP2-RCP26_2030'): [1.8391922681749882, 0.006631959383662307],\n",
       " (2040,\n",
       "  'd872e0d78319cb13e12b96de83e19dd7',\n",
       "  'SSP2-RCP19_2040'): [1.664174817198441, 0.005990449802518106],\n",
       " (2040,\n",
       "  'd872e0d78319cb13e12b96de83e19dd7',\n",
       "  'SSP2-RCP26_2040'): [1.7739710922834737, 0.006256772480144479],\n",
       " (2040,\n",
       "  'a5f2280b72eab45fac5be638870c61ae',\n",
       "  'SSP2-RCP19_2040'): [-0.061773535038168695, -0.000566683393259233],\n",
       " (2040,\n",
       "  'a5f2280b72eab45fac5be638870c61ae',\n",
       "  'SSP2-RCP26_2040'): [-0.0625605206879309, -0.0005684990797994778]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GiveMeName.aggregator(results, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'green': {(2036,\n",
       "   'd872e0d78319cb13e12b96de83e19dd7',\n",
       "   'SSP2-RCP19_2030'): [1.704690182464366, 0.0061609604473516445],\n",
       "  (2036,\n",
       "   'd872e0d78319cb13e12b96de83e19dd7',\n",
       "   'SSP2-RCP26_2030'): [1.8391922681749882, 0.006631959383662307],\n",
       "  (2040,\n",
       "   'd872e0d78319cb13e12b96de83e19dd7',\n",
       "   'SSP2-RCP19_2040'): [1.664174817198441, 0.005990449802518106],\n",
       "  (2040,\n",
       "   'd872e0d78319cb13e12b96de83e19dd7',\n",
       "   'SSP2-RCP26_2040'): [1.7739710922834737, 0.006256772480144479],\n",
       "  (2040,\n",
       "   'a5f2280b72eab45fac5be638870c61ae',\n",
       "   'SSP2-RCP19_2040'): [-0.061773535038168695, -0.000566683393259233],\n",
       "  (2040,\n",
       "   'a5f2280b72eab45fac5be638870c61ae',\n",
       "   'SSP2-RCP26_2040'): [-0.0625605206879309, -0.0005684990797994778]},\n",
       " 'rabbit': {(2036,\n",
       "   'd872e0d78319cb13e12b96de83e19dd7',\n",
       "   'SSP2-RCP19_2030'): [3.409380364928732, 0.012321920894703289],\n",
       "  (2036,\n",
       "   'd872e0d78319cb13e12b96de83e19dd7',\n",
       "   'SSP2-RCP26_2030'): [3.6783845363499763, 0.013263918767324615],\n",
       "  (2036,\n",
       "   '92d2cd69b744fb751c6e0751c3a2b5a6',\n",
       "   'SSP2-RCP19_2030'): [0.31248275940068315, 0.0011854433666807695],\n",
       "  (2036,\n",
       "   '92d2cd69b744fb751c6e0751c3a2b5a6',\n",
       "   'SSP2-RCP26_2030'): [0.3498304094147335, 0.0012948274702447343],\n",
       "  (2040,\n",
       "   'd872e0d78319cb13e12b96de83e19dd7',\n",
       "   'SSP2-RCP19_2040'): [3.328349634396882, 0.011980899605036212],\n",
       "  (2040,\n",
       "   'd872e0d78319cb13e12b96de83e19dd7',\n",
       "   'SSP2-RCP26_2040'): [3.5479421845669474, 0.012513544960288957]}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "GiveMeName.poop_to_excel(data, GiveMeName.bd_get_activity, output_file='output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = Product(name='green', amount=1, unit='kg', service_life=20, production_lci= 'd872e0d78319cb13e12b96de83e19dd7',\n",
    "#             eol_lci= 'a5f2280b72eab45fac5be638870c61ae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p2 = Product(name='rabbit', amount=2, unit='kg', service_life=16, production_lci='d872e0d78319cb13e12b96de83e19dd7',\n",
    "#              eol_lci= '92d2cd69b744fb751c6e0751c3a2b5a6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2036, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP19_2030'), (2036, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP26_2030'), (2036, '92d2cd69b744fb751c6e0751c3a2b5a6', 'SSP2-RCP19_2030'), (2036, '92d2cd69b744fb751c6e0751c3a2b5a6', 'SSP2-RCP26_2030')]\n",
      "[(2040, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP19_2040'), (2040, 'd872e0d78319cb13e12b96de83e19dd7', 'SSP2-RCP26_2040'), (2040, 'a5f2280b72eab45fac5be638870c61ae', 'SSP2-RCP19_2040'), (2040, 'a5f2280b72eab45fac5be638870c61ae', 'SSP2-RCP26_2040')]\n"
     ]
    }
   ],
   "source": [
    "def aggregator_for_product_year(lcia_dict, year, product):\n",
    "    # filter the keys in the lcia dictionary for the given year that match the product's production_lci or eol_lci\n",
    "    keys = [key for key in lcia_dict.keys() if key[0] == year and (product.production_lci in key or product.eol_lci in key)]\n",
    "    print(keys)\n",
    "    # Create a new dictionary containing only the relevant keys\n",
    "    aggregated_lcia = {key: [x * product.amount for x in lcia_dict[key]] for key in keys}\n",
    "    return aggregated_lcia\n",
    "\n",
    "def aggregate_timeline(lcia_dict, timeline_points):\n",
    "    results = {}\n",
    "    for year, product in timeline_points:\n",
    "        if year not in results:\n",
    "            results[year] = {}\n",
    "        results[year][product.name] = aggregator_for_product_year(lcia_dict, year, product)\n",
    "    return results\n",
    "\n",
    "timeline_points = tl.points\n",
    "resultv = aggregate_timeline(results, timeline_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2036: {'rabbit': {(2036,\n",
       "    'd872e0d78319cb13e12b96de83e19dd7',\n",
       "    'SSP2-RCP19_2030'): [3.409380364928732, 0.012321920894703289],\n",
       "   (2036,\n",
       "    'd872e0d78319cb13e12b96de83e19dd7',\n",
       "    'SSP2-RCP26_2030'): [3.6783845363499763, 0.013263918767324615],\n",
       "   (2036,\n",
       "    '92d2cd69b744fb751c6e0751c3a2b5a6',\n",
       "    'SSP2-RCP19_2030'): [0.31248275940068315, 0.0011854433666807695],\n",
       "   (2036,\n",
       "    '92d2cd69b744fb751c6e0751c3a2b5a6',\n",
       "    'SSP2-RCP26_2030'): [0.3498304094147335, 0.0012948274702447343]}},\n",
       " 2040: {'green': {(2040,\n",
       "    'd872e0d78319cb13e12b96de83e19dd7',\n",
       "    'SSP2-RCP19_2040'): [1.664174817198441, 0.005990449802518106],\n",
       "   (2040,\n",
       "    'd872e0d78319cb13e12b96de83e19dd7',\n",
       "    'SSP2-RCP26_2040'): [1.7739710922834737, 0.006256772480144479],\n",
       "   (2040,\n",
       "    'a5f2280b72eab45fac5be638870c61ae',\n",
       "    'SSP2-RCP19_2040'): [-0.061773535038168695, -0.000566683393259233],\n",
       "   (2040,\n",
       "    'a5f2280b72eab45fac5be638870c61ae',\n",
       "    'SSP2-RCP26_2040'): [-0.0625605206879309, -0.0005684990797994778]}}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2036, rabbit), (2040, green)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_codes = set([key[1] for product_data in resultv.values() for impacts_data in product_data.values() for key in impacts_data.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'92d2cd69b744fb751c6e0751c3a2b5a6',\n",
       " 'a5f2280b72eab45fac5be638870c61ae',\n",
       " 'd872e0d78319cb13e12b96de83e19dd7'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2036: {'rabbit': {(2036,\n",
       "    'd872e0d78319cb13e12b96de83e19dd7',\n",
       "    'SSP2-RCP19_2030'): [3.409380364928732, 0.012321920894703289],\n",
       "   (2036,\n",
       "    'd872e0d78319cb13e12b96de83e19dd7',\n",
       "    'SSP2-RCP26_2030'): [3.6783845363499763, 0.013263918767324615],\n",
       "   (2036,\n",
       "    '92d2cd69b744fb751c6e0751c3a2b5a6',\n",
       "    'SSP2-RCP19_2030'): [0.31248275940068315, 0.0011854433666807695],\n",
       "   (2036,\n",
       "    '92d2cd69b744fb751c6e0751c3a2b5a6',\n",
       "    'SSP2-RCP26_2030'): [0.3498304094147335, 0.0012948274702447343]}},\n",
       " 2040: {'green': {(2040,\n",
       "    'd872e0d78319cb13e12b96de83e19dd7',\n",
       "    'SSP2-RCP19_2040'): [1.664174817198441, 0.005990449802518106],\n",
       "   (2040,\n",
       "    'd872e0d78319cb13e12b96de83e19dd7',\n",
       "    'SSP2-RCP26_2040'): [1.7739710922834737, 0.006256772480144479],\n",
       "   (2040,\n",
       "    'a5f2280b72eab45fac5be638870c61ae',\n",
       "    'SSP2-RCP19_2040'): [-0.061773535038168695, -0.000566683393259233],\n",
       "   (2040,\n",
       "    'a5f2280b72eab45fac5be638870c61ae',\n",
       "    'SSP2-RCP26_2040'): [-0.0625605206879309, -0.0005684990797994778]}}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "GiveMeName.poop_to_excel(resultv, GiveMeName.bd_get_activity, output_file='output.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
